# Лабораторная работа №0. Установка локальной модели Qwen

## Цель
Целью данной лабораторной работы является установка на рабочую машину локальной модели нейросети Qwen и её запуск с использованием WebUI.

## План
1. Настройка окружения
2. Запуск языковой модели
3. Задания

---

## 1. Настройка окружения

### Установка WebUI
Для работы с языковой моделью была установлена библиотека `text-generation-webui`, которая предоставляет удобный интерфейс для взаимодействия с нейросетями. Следующие шаги были выполнены:

1. Переход по ссылке на репозиторий `text-generation-webui` на GitHub.
2. Скопирован адрес репозитория и создала папку на своем компьютере для установки.
3. Клонирование репозитория с помощью команды:
    ```bash
    git clone https://github.com/oobabooga/text-generation-webui
    ```
4. Переход в директорию репозитория:
    ```bash
    cd text-generation-webui
    ```
5. Создание виртуальной среды и её активировация  (для Windows):
    ```bash
    python -m venv venv
    venv\Scripts\activate
    ```
6. Установка всех зависимостей:
    ```bash
    pip install -r requirements/portable/requirements.txt --upgrade
    ```

### Скачивание модели Qwen
Для скачивания модели Qwen был использован Hugging Face:

1. Переход на страницу с моделью Qwen на Hugging Face.
2. Выбрал модель `Qwen2.5-Omni-3B-Q8_0`.
3. Скачивание модели в формате GGUF.
4. Далее модель была перемещена в папку `user_data/models/Qwen`.

---

## 2. Запуск языковой модели

После настройки окружения и скачивания модели, для запуска WebUI была выполнена команда:
```bash
python server.py
```

### 2.1. Работа с вкладками

После запуска сервера и перехода по ссылке на главный экран WebUI, я оказался на вкладке **Chat**. На главной странице также присутствуют несколько других вкладок, которые имеют различные функциональные возможности.

![1](ЛР0/1.jpg)


При выполнении данной лабораторной работы, были использованны следующие вкладки:

- **Вкладка Chat**: Здесь можно взаимодействовать с моделью, вводя запросы и получая ответы. Также присутствуют функции для создания новых чатов и изменения их настроек.
- **Вкладка Model**: Подключение свой модели Qwen, выбрав нужную модель в выпадающем списке. Эта вкладка позволяла работать с выбранной моделью.
- **Вкладка Parameters**: Здесь можно изменять параметры, которые напрямую влияют на ответы модели, такие как креативность, точность и разнообразие откликов.

## 2.2. Задание 1: Создание системного промпта

Для первого задания мне нужно было создать системный промпт для модели. Начал с того, что указал, что модель должна исполнять роль друга по переписке и должна использовать много эмодзи, после чего попросил ее написать мне приветственное сообщение и "рассказать" как у нее прошел день. 

![2](ЛР0/2.jpg)


## 3. Эксперимент с параметрами модели

### 3.1. Что такое temperature, top_p, top_k, repetition_penalty?

Перед изменением параметров, было изучено, как они влияют на поведение модели:

- **Temperature (Температура)**: Этот параметр управляет креативностью ответов. Чем выше значение (ближе к 1), тем менее предсказуемыми будут ответы, что позволяет модели генерировать более разнообразные и творческие ответы. При значении, близком к 0, ответы становятся более детерминированными и логичными.
- **Top_p (Нахождение вероятности слов)**: Это параметр, который определяет, какой процент вероятностей слов будет учитываться при генерации. С меньшим значением `top_p` модель будет выбирать только наиболее вероятные слова, что сделает ответы более точными, но менее разнообразными.
- **Top_k (Количество наиболее вероятных слов)**: Этот параметр ограничивает количество слов, которые модель будет рассматривать при выборе следующего слова. Чем выше значение `top_k`, тем больше вариантов выбора для следующего слова.
- **Repetition_penalty (Штраф за повторения)**: Этот параметр помогает избежать излишних повторений в ответах. Он штрафует модель за повторение фраз или слов, что делает её ответы более разнообразными.
![3](ЛР0/3.jpg)
### 3.2. Влияние изменения параметров на поведение модели

Был проведён эксперимент с этими параметрами, чтобы понять, как они влияют на ответы модели. Например, при увеличении значения **temperature** и **top_p** ответы стали более разнообразными, но также менее логичными и иногда запутанными. Это позволило модели генерировать креативные и нестандартные ответы, но также и несколько ошибочных.

Когда были уменьшены **temperature** и **top_p**, модель стала более предсказуемой и давала более точные и логичные ответы. Однако, эти ответы стали менее разнообразными, и иногда они выглядели слишком простыми.

При изменении **repetition_penalty** было замечено, что модель стала избегать повторений, но в некоторых случаях это приводило к менее связным ответам, особенно если текст требовал повторов для сохранения логики.

### 3.3. Результат изменения параметров

После значительного изменения параметров текст стал практически бессвязным но очень разнообразным.

![4](ЛР0/4.jpg)

## 4. Скачивание новой версии модели

После была скачана более новая версия модели Qwen. Эта версия имела улучшенную способность к "думанию", то есть к более логичному и осмысленному формированию ответов.

Была выбрана **qwen3-1.7b.q8_0**. После установки новуой модели, я дал ей аналогичное задание, которое было и предыдущей версии.

![5](ЛР0/5.jpg)
**Результат:** Модель справилась с запросом более "творчески", текст был дополнен форматированием, также появилась вкладка "Thinking". Несмотря на меньшее количество параметров чем в прошлой модели, она продемонстррировала по определенным параметрам улучшения, что говорит о большем техническом совершенстве ьолее новой модели.



---

## Заключение

В ходе выполнения лабораторной работы была произвдена установка и настройка модель Qwen, осуществлено ознакомление с различными параметрами, влияющими на её поведение, и протестированы несколько моделей. Параметры **temperature**, **top_p**, **top_k** и **repetition_penalty** оказали значительное влияние на креативность и точность ответов модели. В итоге, новая версия модели показала улучшенные результаты в решении задач, что подтверждает её более высокую эффективность.
