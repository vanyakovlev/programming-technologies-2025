# Отчёт по Лабораторной работе №2

**Тема:** Обучение сверточной нейронной сети на CIFAR-100, сравнение стратегий уменьшения размерности (stride / max pooling / avg pooling), выбор лучшей модели и экспорт в ONNX.

## 1. Цель работы

1. Обучить CNN на выбранных классах CIFAR-100 с использованием GPU.
2. Провести 3 обучения с разными вариантами “пуллинга”:

- уменьшение размерности через **stride** (свёртка с шагом),
- **MaxPooling**,
- **AvgPooling**.

3. Сравнить качество, время обучения и переобучение.
4. Выбрать лучшую конфигурацию, сохранить модель и экспортировать в ONNX.
5. Проверить корректность ONNX-модели через `onnxruntime`.

## 2. Подготовка окружения и данных

### 2.1. Настройка окружения

Подключены основные библиотеки PyTorch, NumPy, инструменты визуализации и пакеты для ONNX:

```python
!pip install onnx onnxscript
!pip install torchsummary onnx onnxruntime
```

### 2.2. Использование GPU

Для ускорения обучения проверена доступность GPU (`!nvidia-smi`) и выбран `device`:

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```

Все вычисления выполняются на GPU через `.to(device)`.

### 2.3. Загрузка CIFAR-100 и выбор классов

Данные CIFAR-100 скачиваются и распаковываются:

```python
!wget -q https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz
!tar -xzf cifar-100-python.tar.gz
```

Выбранные классы по варианту:

```python
CLASSES = [0, 33, 43]
```

Из train/test выбираются только эти классы, а метки перекодируются в диапазон `0..(num_classes-1)`:

```python
mask = np.isin(train_y, CLASSES)
train_X = train_X[mask].copy()
train_y = train_y[mask].copy()
train_y = np.unique(train_y, return_inverse=1)[1]
```

## 3. DataLoader и формат данных

### 3.1. Формат изображений

Исходные данные CIFAR-100 читаются как `(N, 3, 32, 32)` и переводятся в **NHWC** для удобства:

```python
train_X = np.transpose(train_X, [0, 2, 3, 1])  # NCHW -> NHWC
```

### 3.2. DataLoader

Созданы загрузчики данных для обучения и теста. Метки переводятся в one-hot для хранения в датасете, но для `CrossEntropyLoss` дальше используется `argmax`:

```python
tensor_y = F.one_hot(torch.Tensor(y).to(torch.int64),
                     num_classes=len(CLASSES)).float()
```

## 4. Архитектура CNN и варианты уменьшения размерности

### 4.1. Нормализация

В модель добавлен слой `Normalize`:

- перевод значений пикселей из `0..255` в `0..1`
- нормализация по mean/std CIFAR-100
- преобразование NHWC → NCHW (как требует `Conv2d`)

```python
x = input / 255.0
x = (x - self.mean) / self.std
return x.permute(0, 3, 1, 2)
```

### 4.2. CNN-модель

Модель `Cifar100_CNN` состоит из следующих последовательно соединённых слоёв:

- `Conv1 (3 → H) + BatchNorm + ReLU`
- `Conv2 (H → 2H) + BatchNorm + ReLU`
- **уменьшение пространственной размерности** (три варианта: stride-свёртка, Max Pooling или Average Pooling)
- `Conv3 (2H → 4H) + BatchNorm + ReLU`
- `AdaptiveAvgPool2d(1)` (глобальный усредняющий пуллинг)
- `Dropout(0.3)`
- `Linear (4H → num_classes)`

Первый сверточный слой `conv1` обучает 64 фильтра для выделения **простейших признаков изображения**, таких как края, линии и базовые текстуры.
Слой `BatchNorm` нормализует активации, что стабилизирует процесс обучения и ускоряет сходимость модели.
Функция активации `ReLU` вводит нелинейность и пропускает только положительные отклики фильтров, отсекая неинформативные значения.

Глобальный пуллинг `AdaptiveAvgPool2d(1)` усредняет каждую карту признаков (результат работы одного фильтра свёртки) по всей пространственной области, делая выход независимым от размера карт признаков, уменьшая количество параметров перед классификатором и снижая риск переобучения.

## 5. Что сравнивается: stride / max / avg

В данной лабораторной работе сравниваются **три способа уменьшения пространственной размерности карт признаков** в сверточной нейронной сети. Во всех случаях цель одна и та же — **уменьшить размер feature map**, но **способ и свойства уменьшения разные**.

### 5.1. Stride pooling (уменьшение через свёртку с шагом)

```python
self.pool = nn.Conv2d(hidden_size*2, hidden_size*2,
                      kernel_size=3, stride=2, padding=1)
```

В данном варианте уменьшение размерности выполняется **сверточным слоем с шагом stride = 2**.

**Ключевая идея:**
уменьшение размера происходит не за счёт отдельного pooling-оператора, а **за счёт шага свёртки**.

**Особенности:**

- используется **обучаемый сверточный слой**, содержащий веса и смещения;
- параметр `stride = 2` уменьшает ширину и высоту карты признаков в 2 раза;
- веса свёртки **обучаются** и определяют, какую информацию сохранить при сжатии;
- шаг (stride) **не обучается**, а задаётся вручную как гиперпараметр.

**Следствие:**
stride pooling даёт модели больше гибкости, так как сеть сама учится, **какие признаки важнее сохранить**, но за это приходится платить:

- увеличением числа параметров,
- большей вычислительной сложностью,
- более высоким риском переобучения.

### 5.2. Max Pooling

```python
self.pool = nn.MaxPool2d(2)
```

Max Pooling выполняет уменьшение размерности путём выбора **максимального значения** в каждом окне размером 2×2.

**Особенности:**

- слой **не имеет обучаемых параметров**;
- уменьшает размер карты признаков в 2 раза;
- выбирает **наиболее сильную активацию** в локальной области;
- усиливает наиболее выраженные признаки (края, контуры).

**Следствие:**
Max Pooling хорошо подходит для задач классификации, так как:

- подчёркивает наличие признака, а не его точное положение;
- создаёт инвариантность к небольшим сдвигам изображения.

Недостаток — возможная потеря пространственной информации и склонность к переобучению при ярко выраженных признаках.

### 5.3. Average Pooling

```python
self.pool = nn.AvgPool2d(2)
```

Average Pooling уменьшает размер карты признаков за счёт **усреднения значений** в каждом окне 2×2.

**Особенности:**

- **нет обучаемых параметров**;
- уменьшает размер карты признаков в 2 раза;
- сглаживает активации, уменьшая влияние локальных пиков;
- делает представление более «мягким».

**Следствие:**

- снижает чувствительность к шуму,
- уменьшает резкие перепады значений,
- но может «размывать» важные признаки

## 6. Обучение моделей и метрики

### 6.1. Настройки обучения

- `HIDDEN_SIZE = 64`
- `EPOCHS = 50`
- `LEARNING_RATE = 0.001`
- функция потерь: `CrossEntropyLoss`
- оптимизатор: `Adam`

Для каждого варианта пуллинга запускается **идентичный процесс обучения**, что обеспечивает корректное сравнение моделей.
Во время обучения:

- собираются метрики `train_loss` и `train_accuracy`,
- собираются метрики `val_loss` и `val_accuracy`,
- сохраняется состояние модели `best_model_state`, соответствующее максимальному значению `val_accuracy`.

Обучение реализовано в функции `train_model()`.

### 6.2. Процесс обучения

Процесс обучения состоит из двух фаз на каждой эпохе: **обучение на train** и **проверка на test (валидации)**.

#### Обучение на тренировочной выборке

```python
model.train()
for inputs, labels in dataloader['train']:
    outputs = model(inputs)
    loss = criterion(outputs, labels)

    loss.backward()
    optimizer.step()
```

На этом этапе:

- `model.train()` переводит модель в режим обучения (активны Dropout и BatchNorm);
- выполняется прямой проход (`model(inputs)`), в ходе которого модель формирует предсказания;
- вычисляется функция потерь `loss`;
- вызывается `loss.backward()` для вычисления градиентов;
- `optimizer.step()` обновляет веса модели.

Таким образом, модель **обучается**, постепенно уменьшая значение функции потерь на обучающей выборке.

#### Проверка на валидационной (test) выборке

```python
model.eval()
with torch.no_grad():
    for inputs, labels in dataloader['test']:
        val_outputs = model(inputs)
        val_loss = criterion(val_outputs, labels)
```

На этом этапе:

- `model.eval()` переводит модель в режим оценки (Dropout отключён, BatchNorm работает по накопленной статистике);
- `torch.no_grad()` отключает вычисление градиентов, ускоряя вычисления и снижая расход памяти;
- модель **не обучается**, а только оценивает качество на новых данных.

Данный этап необходим для оценки способности модели **обобщать**, а не запоминать тренировочные данные.

### 6.3. Контроль переобучения

Степень переобучения оценивается как разница между точностью на обучающей и валидационной выборках:

```
overfitting = final_train_acc - final_val_acc
```

Чем больше разница, тем сильнее модель переобучается и тем хуже она обобщает знания на новых данных.

### 6.4. Замер времени обучения

Для каждого варианта пуллинга измеряется время обучения:

```python
start_time = time.time()
...
training_time = end_time - start_time
```

Это позволяет сравнить не только качество моделей, но и их **вычислительную эффективность**.
Как правило, модель со stride-пулингом обучается медленнее из-за наличия обучаемых параметров, тогда как Max и Average Pooling работают быстрее.

## 7. Сравнение результатов обучения (актуальные данные)

На основе логов обучения для трёх вариантов уменьшения размерности (**stride / max / avg**) была составлена сводная таблица результатов.

### Сводная таблица результатов

| **Метрика**                               | **Stride Pooling** | **Max Pooling**  | **Avg Pooling**  | **Лучший вариант** |
| ----------------------------------------- | ------------------ | ---------------- | ---------------- | ------------------ |
| **Лучшая Val Accuracy**                   | **0.9600**         | 0.9567           | 0.9533           | **Stride**         |
| **Final Train Accuracy**                  | **0.9853**         | 0.9873           | 0.9713           | Max                |
| **Final Val Accuracy**                    | **0.9433**         | 0.9333           | 0.7767           | **Stride**         |
| **Степень переобучения**<br>(Train − Val) | **0.0420**         | 0.0540           | 0.1946           | **Stride**         |
| **Время обучения (сек)**                  | 42.07              | **31.23**        | 31.51            | **Max / Avg**      |
| **Тестовая Accuracy**                     | **0.9433**         | _не вычислялась_ | _не вычислялась_ | **Stride**         |

### Как считалось переобучение

- **Stride:**
  `0.9853 − 0.9433 = 0.0420`
- **Max:**
  `0.9873 − 0.9333 = 0.0540`
- **Avg:**
  `0.9713 − 0.7767 = 0.1946`

### Анализ результатов

- **Stride Pooling**

  - Лучшая валидационная точность (**0.9600**)
  - Минимальное переобучение
  - Лучшая обобщающая способность
  - Самое долгое обучение (из-за обучаемых весов)

- **Max Pooling**

  - Почти максимальная точность
  - Быстрое обучение
  - Чуть сильнее переобучается, чем stride

- **Average Pooling**

  - Быстрое обучение
  - Значительно хуже финальная val accuracy
  - Сильное переобучение из-за «размывания» признаков

Несмотря на более длительное время обучения, **модель со stride pooling** показала:

- наивысшую валидационную точность,
- наименьшую степень переобучения,
- наилучшую устойчивость к обобщению.

Поэтому именно **stride pooling** была выбрана как **лучшая конфигурация** и использована для финальной оценки на тестовой выборке и экспорта в ONNX.

## 8. Оценка лучшей модели на тестовой выборке

После выбора лучшей модели (**Stride Pooling**) была выполнена оценка качества на тестовой выборке с использованием `classification_report`, который рассчитывает метрики **precision**, **recall** и **F1-score** для каждого класса.

```python
print(classification_report(all_labels, all_preds,
                           target_names=[str(cls) for cls in CLASSES],
                           digits=4))
```

### Результаты классификации

| Класс            | Precision | Recall | F1-score   | Support |
| ---------------- | --------- | ------ | ---------- | ------- |
| 0                | 0.9798    | 0.9700 | 0.9749     | 100     |
| 33               | 0.9143    | 0.9600 | 0.9366     | 100     |
| 43               | 0.9375    | 0.9000 | 0.9184     | 100     |
| **Accuracy**     |           |        | **0.9433** | 300     |
| **Macro avg**    | 0.9439    | 0.9433 | 0.9433     | 300     |
| **Weighted avg** | 0.9439    | 0.9433 | 0.9433     | 300     |

### Пояснение метрик

- **Precision (точность)** показывает, какая доля объектов, отнесённых моделью к данному классу, действительно принадлежит этому классу.
  Высокие значения precision означают малое количество ложных срабатываний.

- **Recall (полнота)** показывает, какую долю объектов данного класса модель смогла правильно обнаружить.
  Высокий recall означает, что модель редко «пропускает» объекты класса.

- **F1-score** является гармоническим средним между precision и recall и отражает баланс между этими метриками.

### Анализ по классам

- **Класс 0**
  Обладает наивысшими значениями precision (0.9798) и recall (0.9700), что говорит о точной и устойчивой классификации данного класса.

- **Класс 33**
  Имеет высокий recall (0.9600), что означает хорошее обнаружение объектов данного класса, при немного более низком precision (0.9143), указывающем на наличие небольшого количества ложных срабатываний.

- **Класс 43**
  Демонстрирует сбалансированные значения precision (0.9375) и recall (0.9000), что свидетельствует о стабильном, но несколько более сложном для модели классе.

### Общий вывод по тестовой выборке

Модель со **stride pooling** показала высокое и сбалансированное качество классификации на тестовой выборке.
Общая точность (**Accuracy = 0.9433**) подтверждает хорошую обобщающую способность модели.

Схожие значения **macro avg** и **weighted avg** указывают на отсутствие перекоса в сторону отдельных классов и равномерное качество классификации по всем классам.

## 9. Экспорт в ONNX и проверка

### 9.1. Загрузка сохранённой модели (эмуляция перезапуска среды)

Модель загружается из `best_cifar100_model.pth`, пересоздаётся архитектура и подгружаются веса.

### 9.2. Экспорт

Экспорт выполняется через `torch.onnx.export`, вход — тензор в формате **NHWC**:

```python
dummy_input = torch.randn(1, 32, 32, 3, device=device)
```

Результат: файл `cifar100_model.onnx`.

### 9.3. Проверка

ONNX-модель:

- проверяется `onnx.checker.check_model`
- запускается инференс через `onnxruntime.InferenceSession`

## 10. Итоговое заключение

В рамках лабораторной работы была реализована и обучена сверточная нейронная сеть для классификации изображений CIFAR-100 по трём выбранным классам **[0, 33, 43]** с использованием GPU. Были обучены и сравнены три варианта уменьшения размерности карт признаков: **stride pooling, Max Pooling и Average Pooling**.

По результатам экспериментов модель со **stride pooling** показала наилучшие результаты по валидационной точности и минимальную степень переобучения, а также продемонстрировала высокое качество классификации на тестовой выборке (**Accuracy = 0.9433**). Лучшая модель была сохранена и успешно экспортирована в формат **ONNX**, что подтверждает корректность её работы вне среды PyTorch.

**Ссылка на выполнение лабораторной работы в Google Colab:**
[https://colab.research.google.com/drive/1eGMZKR1m9hucPfLRQ-nUOQOaFWGNmcVI?usp=sharing](https://colab.research.google.com/drive/1eGMZKR1m9hucPfLRQ-nUOQOaFWGNmcVI?usp=sharing)
