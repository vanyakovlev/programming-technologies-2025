 # Лабораторная работа №2-2 (Беляев И.С.). Отчёт.

## Задание.
По заданию выбрать свои классы и обучить сверточную нейронную сеть из примера, используя GPU, а затем повысить точность модели.
Провести три обучения для 3 разных тактик пуллинга: пуллинг с помощью шага свёртки stride, макс пуллинг, усредняющий пуллинг.
Сравнить достигнутое качество, время обучения и степень переобучения. Выбрать лучшую конфигурацию. Сохранить модель. Перезапустить среду выполнения - теряются
все текующие переменные.

## Этап №1. Подготовка необходимых модулей и ввод данных.
Первым делом необхоодимо было подготовить все нужные библиотеки. В данной лабораторной работе были использованы такие библиотеки как:
- numpy: Библиотека для работы с многомерными массивами и математическими операциями;
- torch: Основной фреймворк для глубокого обучения; предоставляет тензоры с GPU-поддержкой, автодифференцирование и базовые инструменты для моделей;
- torchsummary: Инструмент для вывода summary модели; показывает слои, параметры и размеры, как в Keras;
- pickle: Стандартная библиотека для сериализации; нужна для чтения pickle-файлов датасета CIFAR-100;
- classification_report: Функция из scikit-learn; генерирует отчёт с precision, recall, f1 для оценки классификации;
- PIL: Библиотека Pillow для изображений; используется для открытия, манипуляции и отображения картинок;
- tqdm: Библиотека для прогресс-баров; оборачивает циклы (эпохи/батчи) для визуализации прогресса обучения;
- clear_output: Функция IPython; очищает вывод в Jupyter/Colab для динамического обновления логов или графиков;
- matplotlib: Библиотека для визуализации; рисует графики loss/accuracy и показывает изображения.

Затем, мы определили видеокарту для того, чтобы нейронная сеть обучалась быстрее:

![Определяем GPU](https://github.com/NP1R777/programming-technologies-2025/blob/Laba_2_Belyev/students/IS22/Zaharov%20Ilia/Lab2-2/pictures/image1.png)

## Этап №2. Подготовка тренировочной и тестовой выборок и их чтение.
На втором этапе мы скачали данные CIFAR100 и сформировали тренировочную и тестовую выборки. В данном варианте, мне попалась выборка с яблоками.

![Картинка с выборки](https://github.com/NP1R777/programming-technologies-2025/blob/Laba_2_Belyev/students/IS22/Zaharov%20Ilia/Lab2-2/pictures/image2.png)

Далее было принято решение создать `Pytorch DataLoader` для удобной манипуляции данными и перейти к следующему этапу.

## Этап №3. Создание Pytorch модели сверточной нейронной сети.
На данном этапе определяются три класса PyTorch-модулей для CNN:
- Normalize нормализует входные изображения (делит на 255, вычитает среднее и делит на std, переставляет оси в NCHW);
- GlobalMaxPool2d выполняет адаптивный max-pooling до 1x1 и flatten (но не используется в модели);
- Cifar100_CNN — основная сеть для CIFAR-100, с последовательностью слоёв в nn.Sequential:
  - BatchNorm2d(3) — Нормализация входных изображений. Первый слой принимает RGB-изображения (3 канала) и автоматически выравнивает их яркость и контраст.
  - Conv2d(3→64, kernel=3, stride=4, padding=1) — Свёртка с уменьшением размера. Эта свёртка выполняет две ключевые задачи одновременно:
    - Извлекает простые визуальные признаки (грани, текстуры) с помощью 64 фильтров 3×3.
    - Уменьшает размер карты признаков в 4 раза за счёт шага (stride=4). Выходной размер — 8×8 (было 32×32).
    - Padding=1 сохраняет чётность размеров при агрессивном уменьшении.
  - ReLU() — Активация нелинейности. Применяет функцию max(0, x) ко всем элементам. "Обнуляет" отрицательные активации, оставляя только значимые положительные      признаки. Это вводит нелинейность, без чего сеть была бы просто линейным преобразованием.
  - Conv2d(64→128, kernel=3, stride=1, padding=1) — Углубление представления признаков. Работает с уже извлечёнными признаками (64 канала), комбинируя их в         более сложные паттерны (например, контуры объектов). Использует 128 фильтров 3×3 с шагом 1, поэтому пространственный размер не меняется (остаётся 8×8).
    Увеличивает "ёмкость" модели.
  - ReLU() — Повторная активация. Снова добавляет нелинейность после второй свёртки, позволяя модели описывать более сложные зависимости между признаками.
  - AvgPool2d(kernel_size=8) — Глобальное усреднение. Принимает карты признаков размером 8×8 и усредняет все значения в каждом из 128 каналов. Превращаеткаждый     канал в одно число — "глобальный дескриптор". На выходе получается вектор из 128 чисел, который уже не содержит пространственной информации, но кодирует        смысловое содержание изображения. Это эффективная замена полносвязным слоям.

Вот сводка по модели:

![Описание модели](https://github.com/NP1R777/programming-technologies-2025/blob/Laba_2_Belyev/students/IS22/Zaharov%20Ilia/Lab2-2/pictures/image3.png)

Ниже представлен код написанной модели, с подробными комментариями:
```
class Normalize(nn.Module):
    def __init__(self, mean, std):
        super(Normalize, self).__init__()
        self.mean = torch.tensor(mean).to(device)
        self.std = torch.tensor(std).to(device)

    def forward(self, input):
        x = input / 255.0
        x = x - self.mean
        x = x / self.std
        return x.permute(0, 3, 1, 2) # nhwc -> nm

class GlobalMaxPool2d(nn.Module):
    def __init__(self):
        super(GlobalMaxPool2d, self).__init__()

    def forward(self, input):
        out = F.adaptive_max_pool2d(input, output_size=1)
        return out.flatten(start_dim=1)

class Cifar100_CNN(nn.Module):
    def __init__(self, hidden_size=32, classes=100):
        super(Cifar100_CNN, self).__init__()
        # https://blog.jovian.ai/image-classification-of-cifar100-dataset-using-pytorch-8b7145242df1
        self.seq = nn.Sequential(
            Normalize([0.5074,0.4867,0.4411],[0.2011,0.1987,0.2025]),
            # первый способ уменьшения размерности картинки - через stride
            nn.Conv2d(3, HIDDEN_SIZE, 5, stride=4, padding=2),
            nn.ReLU(),
            # второй способ уменьшения размерности картинки - через слой пуллинг
            nn.Conv2d(HIDDEN_SIZE, HIDDEN_SIZE*2, 3, stride=1, padding=1),
            nn.ReLU(),
            nn.AvgPool2d(4),#nn.MaxPool2d(4),
            nn.Flatten(),
            nn.Linear(HIDDEN_SIZE*8, classes),
        )

    def forward(self, input):
        return self.seq(input)

HIDDEN_SIZE = 32
model = Cifar100_CNN(hidden_size=HIDDEN_SIZE, classes=len(CLASSES))
# NEW
model.to(device)
print(model(torch.rand(1, 32, 32, 3).to(device)))
summary(model, input_size=(32, 32, 3))
model
```

## Этап 4. Обучение модели по эпохам.
На данном этапе предстояло обучить созданную выше модель на загруженных данных.

Здесь мы реализовали цикл обучения сверточной нейронной сети (модели из предыдущего фрагмента) на загруженном датасете в `PyTorch`
на 500 эпохах `EPOCHS=500`, с использованием прогресс-бара от `tqdm` для отслеживания прогресса `общий — 500 эпох * батчей в train`.

В каждой эпохе модель переводится в режим обучения `model.train()`, и для каждого батча из `train DataLoader`: данные перемещаются на device `GPU`, обнуляются градиенты, вычисляется `forward-pass outputs = model(inputs)`, `loss (CrossEntropy, criterion)` и `accuracy (сравнение argmax)`, затем backward и шаг оптимизатора `optimizer.step()`; статистика `(loss, acc)` собирается в список `tmp` для усреднения/перцентилей.

После `train` модель переводится в eval-режим `model.eval()`, и аналогично вычисляется loss/acc на val (test) DataLoader без градиентов `with torch.no_grad()`.

Каждые 20 эпох `REDRAW_EVERY=20` очищается вывод `clear_output`, обновляется прогресс-бар, и рисуются два графика `Matplotlib`: слева — `CrossEntropy loss (CCE)` для train/val с заполнением между 25-75 перцентилями, справа — accuracy; графики обновляются динамически. В конце выводится общее время обучения в секундах (passed).

Это позволяет мониторить сходимость, переобучение (train vs val) и качество в реальном времени, с акцентом на статистику по батчам.

Графики ниже отражают итог обучения модели:

![Графики обучения нейронной сети](https://github.com/NP1R777/programming-technologies-2025/blob/Laba_2_Belyev/students/IS22/Zaharov%20Ilia/Lab2-2/pictures/image4.png)

Ниже так же представлен код для более полного понимания того, как проходило обучение и что конкретно использовалось в коде:
```
EPOCHS = 500
REDRAW_EVERY = 20
steps_per_epoch = len(dataloader['train'])
steps_per_epoch_val = len(dataloader['test'])
# NEW
pbar = tqdm(total=EPOCHS*steps_per_epoch)
losses = []
losses_val = []
passed = 0
for epoch in range(EPOCHS):  # проход по набору данных несколько раз
    #running_loss = 0.0
    tmp = []
    model.train()
    for i, batch in enumerate(dataloader['train'], 0):
        # получение одного минибатча; batch это двуэлементный список из [inputs, labels]
        inputs, labels = batch
        # на GPU
        inputs, labels = inputs.to(device), labels.to(device)

        # очищение прошлых градиентов с прошлой итерации
        optimizer.zero_grad()

        # прямой + обратный проходы + оптимизация
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        #loss = F.cross_entropy(outputs, labels)
        loss.backward()
        optimizer.step()

        # для подсчёта статистик
        #running_loss += loss.item()
        accuracy = (labels.detach().argmax(dim=-1)==outputs.detach().argmax(dim=-1)).\
                    to(torch.float32).mean().cpu()*100
        tmp.append((loss.item(), accuracy.item()))
        pbar.update(1)
    #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / steps_per_epoch:.3f}')
    losses.append((np.mean(tmp, axis=0),
                   np.percentile(tmp, 25, axis=0),
                   np.percentile(tmp, 75, axis=0)))
    #running_loss = 0.0
    tmp = []
    model.eval()
    with torch.no_grad(): # отключение автоматического дифференцирования
        for i, data in enumerate(dataloader['test'], 0):
            inputs, labels = data
            # на GPU
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            #running_loss += loss.item()
            accuracy = (labels.argmax(dim=-1)==outputs.argmax(dim=-1)).\
                        to(torch.float32).mean().cpu()*100
            tmp.append((loss.item(), accuracy.item()))
    #print(f'[{epoch + 1}, {i + 1:5d}] val loss: {running_loss / steps_per_epoch_val:.3f}')
    losses_val.append((np.mean(tmp, axis=0),
                       np.percentile(tmp, 25, axis=0),
                       np.percentile(tmp, 75, axis=0)))
    if (epoch+1) % REDRAW_EVERY != 0:
        continue
    clear_output(wait=False)
    passed += pbar.format_dict['elapsed']
    pbar = tqdm(total=EPOCHS*steps_per_epoch, miniters=5)
    pbar.update((epoch+1)*steps_per_epoch)
    x_vals = np.arange(epoch+1)
    _, ax = plt.subplots(1, 2, figsize=(15, 5))
    stats = np.array(losses)
    stats_val = np.array(losses_val)
    ax[1].set_ylim(stats_val[:, 0, 1].min()-5, 100)
    ax[1].grid(axis='y')
    for i, title in enumerate(['CCE', 'Accuracy']):
        ax[i].plot(x_vals, stats[:, 0, i], label='train')
        ax[i].fill_between(x_vals, stats[:, 1, i],
                           stats[:, 2, i], alpha=0.4)
        ax[i].plot(x_vals, stats_val[:, 0, i], label='val')
        ax[i].fill_between(x_vals,
                           stats_val[:, 1, i],
                           stats_val[:, 2, i], alpha=0.4)
        ax[i].legend()
        ax[i].set_title(title)
    plt.show()
print('Обучение закончено за %s секунд' % passed)
```

Затем, было принято решение проверить качество обучения модели по классам на обучающей и тестовой выборке. Ниже представлены результаты данной проверки:

![Проверка обучения модели](https://github.com/NP1R777/programming-technologies-2025/blob/Laba_2_Belyev/students/IS22/Zaharov%20Ilia/Lab2-2/pictures/image5.png)

Код для проверки обучения модели нейронной сети, написанной на предыдущих шагах:
```
for part in ['train', 'test']:
    y_pred = []
    y_true = []
    with torch.no_grad(): # отключение автоматического дифференцирования
        for i, data in enumerate(dataloader[part], 0):
            inputs, labels = data
             # на GPU
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs).detach().cpu().numpy()
            y_pred.append(outputs)
            y_true.append(labels.cpu().numpy())
        y_true = np.concatenate(y_true)
        y_pred = np.concatenate(y_pred)
        print(part)
        print(classification_report(y_true.argmax(axis=-1), y_pred.argmax(axis=-1),
                                    digits=4, target_names=list(map(str, CLASSES))))
        print('-'*50)
```

## Этап №4. Сохранение модели в ONNX.
Для начала необходимо разобраться с тем, что же такое ONNX?
ONNX (Open Neural Network Exchange) — это открытый стандарт и формат для представления моделей машинного обучения (включая глубокие нейронные сети).
Он позволяет экспортировать модели из одного фреймворка (например, PyTorch, TensorFlow, scikit-learn) и запускать их в другом, без переобучения,
обеспечивая интероперабельность между инструментами, аппаратными платформами и средами.
После несложных манипуляций, модель была сохранена в данном формате:

```
RuntimeError: /github/workspace/onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $16 for Identity
[torch.onnx] Run decomposition... ✅
[torch.onnx] Translate the graph into ONNX...
[torch.onnx] Translate the graph into ONNX... ✅
ONNXProgram(
    model=
        <
            ir_version=10,
            opset_imports={'': 18},
            producer_name='pytorch',
            producer_version='2.9.0+cu126',
            domain=None,
            model_version=None,
        >
        graph(
            name=main_graph,
            inputs=(
                %"input"<FLOAT,[s31,32,32,3]>
            ),
            outputs=(
                %"output"<FLOAT,[1,3]>
            ),
            initializers=(
                %"seq.1.bias"<FLOAT,[32]>{TorchTensor(...)},
                %"seq.3.bias"<FLOAT,[64]>{TorchTensor(...)},
                %"seq.7.weight"<FLOAT,[3,256]>{TorchTensor(...)},
                %"seq.7.bias"<FLOAT,[3]>{TorchTensor<FLOAT,[3]>(Parameter containing: tensor([ 0.5177, -0.5444, -0.4557], device='cuda:0', requires_grad=True), name='seq.7.bias')},
                %"seq.0.mean"<FLOAT,[3]>{TorchTensor<FLOAT,[3]>(tensor([0.5074, 0.4867, 0.4411], device='cuda:0'), name='seq.0.mean')},
                %"seq.0.std"<FLOAT,[3]>{TorchTensor<FLOAT,[3]>(tensor([0.2011, 0.1987, 0.2025], device='cuda:0'), name='seq.0.std')},
                %"seq.1.weight"<FLOAT,[32,3,5,5]>{TorchTensor(...)},
                %"seq.3.weight"<FLOAT,[64,32,3,3]>{TorchTensor(...)},
                %"val_4"<INT64,[2]>{Tensor<INT64,[2]>(array([  1, 256]), name='val_4')},
                %"val_0"<FLOAT,[]>{Tensor<FLOAT,[]>(array(255., dtype=float32), name='val_0')}
            ),
        ) {
```

В данном фрагменте показана только часть данного формата, так как показывать его полностью не целесообразно из-за очень большого количества полей. По сути,
данный формат сохранени моделей нейронных сетей очень схож с `JSON`, однако он немного видоизменён для того, чтобы оптимально работать с моделями нейронных сетей. Код для сохранения модели предстален ниже:

```
# входной тензор для модели
x = torch.randn(1, 32, 32, 3, requires_grad=True).to(device)
torch_out = model(x)

# экспорт модели
torch.onnx.export(model,               # модель
                  x,                   # входной тензор (или кортеж нескольких тензоров)
                  "cifar100_CNN.onnx", # куда сохранить (либо путь к файлу либо fileObject)
                  export_params=True,  # сохраняет веса обученных параметров внутри файла модели
                  opset_version=9,     # версия ONNX
                  do_constant_folding=True,  # следует ли выполнять укорачивание констант для оптимизации
                  input_names = ['input'],   # имя входного слоя
                  output_names = ['output'],  # имя выходного слоя
                  dynamic_axes={'input' : {0 : 'batch_size'},    # динамичные оси, в данном случае только размер пакета
                                'output' : {0 : 'batch_size'}})
```

## Вывод.
В ходе выполнения лабораторной работы была написана нейронная сеть свёрточного типа. Так же была освоена библиотека `ONNX`, которая позволяет сохранять модели нейронных сетей в более удобном формате. Если подытожить, то теперь имеется более полное представление о нейронных сетях свёрточного типа, и их главном отличии от сетей другого типа - это фильтр, и вот тут стоит остановиться подробнее.
По своей сути, фильтр — это небольшая матрица чисел (обычно размером 3×3, 5×5). Эти числа — веса, которые сеть учится в процессе тренировки. Фильтр не ищет предметы целиком (например, кошку или автомобиль). Вместо этого он настроен на обнаружение простейших визуальных примитивов:
- Вертикальных или горизонтальных граней (перепадов яркости).
- Углов и изгибов.
- Пятен цвета или определённых текстур.
- Конкретных геометрических паттернов.

Фильтр — это основа всей свёрточной операции, его «знания» о том, как выглядит нужный ему признак.
В остальном, процесс обучения нейронной сети такого типа очень схож с сетями других типов.

Ссылка на блокнот в Google Collab:
https://colab.research.google.com/drive/1AmWOvYi8cci7lw3rLEUlxT3JOPVNJ3UG?usp=sharing
