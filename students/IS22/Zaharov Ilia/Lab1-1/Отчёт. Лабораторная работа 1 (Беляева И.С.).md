# Отчёт. Лабораторная работа №1. Введение в DL.
## Задание
Необходимо познакомиться с фреймворком машинного обучения PyTorch и выполнить три задания:
 - Регрессия по теореме универсальной аппроксимации, ручное дифференцирование
 - Бинарная классификация с помощью автодиффиренцирования PyTorch
 - Обучить полносвязную нейронную сеть классификации 3 классов изображений из набора данных CIFAR100 по варианту из примера и затем повысить точность на тестовой выборке.

## Задание №1. Регрессия по теореме универсальной аппроксимации, ручное дифференцирование.
Теорема универсальной аппроксимации гласит, что нейронная сеть с одним скрытым слоем (при достаточном числе нейронов) может приблизить любую непрерывную функцию с заданной точностью.
Регрессия — задача предсказания непрерывного значения. Для обучения сети используется **градиентный спуск**, требующий вычисления производных (дифференцирования).
Ручное дифференцирование — это аналитическое вычисление частных производных функции потерь по весам сети (например, для MSE: ∂L/∂w). Используется правило цепочки (chain rule) для многослойных сетей.
Пример: Для нейрона с активацией σ(z) = 1/(1+e⁻ᶻ) производная ∂σ/∂z = σ(z)(1−σ(z)).
На данном этапе лабораторной работы, необходимо было реализовать этот механизм при помощи средст языка программирования Python. В этом нам помогли библиотеки
`numpy` и `PyTorch`. Для отображения получившихся результатов была использована библиотека `matplotlib`.

![Результат подготовки данных](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image1.png)

На данном этапе, мы просто подготовили данные и инициализировали простую нейронную сеть для обучения на зашумлённой сигмоидальной функции.
После подготовительного этапа, было принято решения обучить нейронную сеть для решения поставленной задачи. Это делалост с помощью классического алгоритма обучения
нейронных сетей, всем известный - `градиентный спуск`. Если вкратце, принцип этого алгоритма очень прост, мы задаём то значение, которое хотим получить от нейронной сети,
затем идём вперёд по слоям сети, после чего вычисляем ошибку, то есть то, насколько желаемый ответ отличается от ответа нейронной сети, затем идём назад по слоям
сети для корректировки весов, и так до тех пор, пока мы не получим желаемое значение.

![Результат обучения нейронной сети](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image2.png)
![Графическое отображение результатов](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image3.png)
На данном графике видно, что теперь, сигмоидная функция не имеет шумов, а значит, задача выполнена, нейронная сеть обучена и решает поставленную задачу. Это так же
доказывают цифры из консоли, на них видно, как ошибка становится всё меньше и меньше.

## Задание №2. Бинарная классификация с помощью автодифференцирования PyTorch.
Если вкратце, то бинарная классификация с автодифференцированием в PyTorch — это процесс обучения модели, которая предсказывает один из двух классов (например, 0 или 1).
Для начала, было принято решение подготовить данные для задачи классификации. На графике ниже можно посмотреть, что у нас есть 2 класса:

![Графическое отображение подготовленных данных](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image4.png)

После подготовки данных началось обучение нейронной сети для новой задачи: бинарной классификации. Обучение происходило по использовавшемуся выше алгоритму, однако
была добавлена некоторая оптимизация. Была написана функция потербь, для более точного понимания как проходит обучение и определена новая функция активации, которая
лучше подходит для выполнения данной задачи.

![Отображение функции потерь](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image5.png)

По представленному выше скриншоту видно, что функция потерь начала стремительно падать вниз, а это значит, что обучение прошло успешно. Следующим шагом было
необходимо проверить результат обучения. Если нейронная сеть сможет отличить скопление жёлтых точек от фиолетовых - значит, она может решать поставленную задачу.
На скриншоте ниже видно, что задачу нейронная сеть решает безукоризненно.

![Проверка результатов обучения](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image6.png)

## Задание №3. Классификация изображений CIFAR100.
Классификация изображений CIFAR-100 — это задача компьютерного зрения, в которой модель должна определить, к какому из 100 классов относится изображение. Датасет CIFAR-100 содержит 60 000 цветных изображений размером 32×32 пикселя, равномерно распределённых по 100 классам (по 600 изображений на класс: 500 для обучения и 100 для тестирования). Классы объединены в 20 суперкатегорий (например, "животные", "транспорт", "растения").
Для начала было принято решение загрузить датасет и прочитать из него нужные данные. Промежуточный результат можно посмотреть ниже:

![Выбранный класс изображений](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image7.png)

На данном изображении видно, что для поставленной задачи был выбран класс изображений, в котором содержатся картинки с яблоками. Далее было необходимо обучить нейронную сеть на данной выборке. Для этого был создан `PyTorchLoader` для удобной "подачи" изображений в нейронную сеть и `PyTorch модель многослойного персептрона с одним открытым слоем`. После этого для ускорения обучения был создан `оптимизатор градиентного спука` и выбрана кросс-энтропийная функция активации. После подготовки всех данных было принято решение начать обучение построенной нейронной сети. Результаты можно увидеть ниже:

![Результаты обучения](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image8.png)

![Проверка качества модели](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image9.png)

![Графическое отображение результатов обучения](https://github.com/NP1R777/programming-technologies-2025/blob/main/students/IS22/Zaharov%20Ilia/Lab1-1/images/image10.png)

Ссылка на Google Collad, в котором была выполнена работа: https://colab.research.google.com/drive/1vjaHbxCbF4DcbcttxA1aXnyxGCGlui4_#scrollTo=ckRdK1RcE990
